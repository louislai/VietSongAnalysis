{
 "metadata": {
  "name": "",
  "signature": "sha256:a485a61ea6d33527e7614d05c645fbecee573537a5b4110506fd2b5a19d22499"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark import SparkConf, SparkContext, SQLContext\n",
      "import pyspark.sql.functions as func\n",
      "\n",
      "spark = pyspark.sql.SparkSession.builder\\\n",
      "    .master(\"local\") \\\n",
      "    .appName('app')\\\n",
      "    .getOrCreate()\n",
      "sc = spark.sparkContext"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "\n",
      "print(sys.executable)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/usr/bin/python\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#help(spark.read.csv)\n",
      "\n",
      "songs = spark.read.csv('file:///home/hadoop/spark-data/dataset/songs.csv', header=True, sep=\",\")\n",
      "performers = spark.read.csv('file:///home/hadoop/spark-data/dataset/performers.csv', header=True, sep=\",\")\n",
      "genres = spark.read.csv('file:///home/hadoop/spark-data/dataset/genres.csv', header=True, sep=\",\")\n",
      "\n",
      "songs.show()\n",
      "performers.show()\n",
      "genres.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "+-------+--------------------+--------------------+--------------------+\n",
        "|song_id|                name|              artist|               lyric|\n",
        "+-------+--------------------+--------------------+--------------------+\n",
        "|   1920|    h\u00e1i hoa b\u00ean r\u1eebng|      d\u00e2n ca gia rai|ta \u0111i h\u00e1i h\u00e1i hoa...|\n",
        "|  10154|        rock rock \u0111i|            qu\u1ed1c b\u1ea3o|rock rock \u0111i h\u1ee1i ...|\n",
        "|   1305|      anh kh\u00f4ng hi\u1ec3u|           b\u1ea3o chinh|nh\u1edb v\u1ec1 em y\u00eau bao...|\n",
        "|  11583|             nh\u1eadt k\u00fd|           th\u1ee7y ti\u00ean|c\u00f3 nh\u1eefng khi bu\u1ed3n...|\n",
        "|   5228|        t\u00ecnh d\u1ea1i kh\u1edd|c\u1ed5 nh\u1ea1c: vi\u1ec5n ch\u00e2...|em \u01a1i th\u1ee9c tr\u1ecdn \u0111...|\n",
        "|   3076|    xin em \u0111\u1eebng kh\u00f3c|        \u0111\u1ed7 \u0111\u00ecnh ph\u00fac|c\u1ed1 n\u00edu k\u00e9o c\u0169ng v...|\n",
        "|   3158|tr\u00ean qu\u00ea h\u01b0\u01a1ng mi...|           phan nh\u00e2n|h\u00f2 \u01a1i\u2026 ng\u1ecdt ng\u00e0o ...|\n",
        "|  10861|s\u00e0i g\u00f2n m\u00e0u xanh ...|           ng\u00f4 hu\u1ef3nh|s\u00e0i g\u00f2n qu\u00ea c\u1ee7a m...|\n",
        "|    734|   v\u1ee3 tuy\u1ec7t v\u1eddi nh\u1ea5t|        v\u01b0\u01a1ng anh t\u00fa|nh\u00ecn em c\u1ea1nh b\u00ean ...|\n",
        "|   6571|          r\u1eebng chi\u1ec1u|            v\u0169 thanh|r\u1eebng chi\u1ec1u nghe l...|\n",
        "|   9716|      khi anh g\u1eb7p em|          b\u1eb1ng c\u01b0\u1eddng|em d\u1ecbu d\u00e0ng nh\u01b0 t...|\n",
        "|    557|        \u0111\u1eebng b\u1eadn t\u00e2m|             to\u00e0n v\u0169|chi\u0309 co\u0300n va\u0300i ph...|\n",
        "|   2932|th\u00eam m\u1ed9t l\u1ea7n y\u00eau ...|       tr\u01b0\u01a1ng l\u00ea s\u01a1n|bao nhi\u00eau cu\u1ed9c vu...|\n",
        "|   2919|      qu\u00e1 kh\u1ee9 v\u00e0 anh|          nguy\u1ec5n h\u1eadu|m\u1edbi h\u00f4m n\u00e0o ng\u01b0\u1eddi...|\n",
        "|  10625|    g\u00f3c ph\u1ed1 d\u1ecbu d\u00e0ng|       tr\u1ea7n minh phi|h\u1ee1i chi\u1ebfc l\u00e1 me x...|\n",
        "|   9297|     th\u1ee9 tha m\u1ed9t l\u1ea7n|     nguy\u1ec5n nh\u1ea5t huy|nghe m\u01b0a r\u01a1i ngo\u00e0...|\n",
        "|   8722|    ng\u01b0\u1eddi t\u00ecnh v\u00f4 t\u01b0|             th\u1ebf b\u1ea3o|bi\u1ec3n ru em bi\u1ec3n n...|\n",
        "|   1154|     xa r\u1ed3i m\u00f9a \u0111\u00f4ng|          nguy\u1ec5n nam|t\u1ea1m bi\u1ec7t t\u1ea1m bi\u1ec7t...|\n",
        "|   3198|    chuy\u1ec7n t\u00ecnh bu\u1ed3n|              \u00e2n nhi|d\u00f2ng ng\u01b0\u1eddi l\u1ea1nh l...|\n",
        "|  11544|       anh c\u00f3 l\u1ed7i g\u00ec|      nguy\u1ec5n \u0111\u00ecnh v\u0169|y\u00eau th\u01b0\u01a1ng l\u00e0 gi\u1eef...|\n",
        "+-------+--------------------+--------------------+--------------------+\n",
        "only showing top 20 rows\n",
        "\n",
        "+-------+--------------------+\n",
        "|song_id|           performer|\n",
        "+-------+--------------------+\n",
        "|   1920|                null|\n",
        "|  10154|                null|\n",
        "|   1305|          s\u01a1n t\u00f9ng m|\n",
        "|   1305|           nam khang|\n",
        "|   1305|            quang h\u00e0|\n",
        "|   1305|         h\u1ed3 anh d\u0169ng|\n",
        "|  11583|           th\u1ee7y ti\u00ean|\n",
        "|  11583|      tr\u1ea7n h\u1ed3ng ki\u1ec7t|\n",
        "|   5228|          m\u1ea1nh qu\u1ef3nh|\n",
        "|   5228|            t\u00e2m \u0111oan|\n",
        "|   5228|   nguy\u1ec5n th\u00e0nh vi\u00ean|\n",
        "|   5228|              l\u00fd h\u1ea3i|\n",
        "|   5228|           tr\u01b0\u1eddng v\u0169|\n",
        "|   5228|           qu\u1ed1c d\u0169ng|\n",
        "|   5228|         nguy\u1ec5n h\u01b0ng|\n",
        "|   5228|            ng\u1ecdc s\u01a1n|\n",
        "|   5228|             v\u0169 h\u00f9ng|\n",
        "|   5228|           ch\u1ebf khanh|\n",
        "|   5228|ng\u1ecdc khang (ca s\u0129...|\n",
        "|   5228|        t\u01b0\u1eddng nguy\u00ean|\n",
        "+-------+--------------------+\n",
        "only showing top 20 rows\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "+-------+--------------+\n",
        "|song_id|         genre|\n",
        "+-------+--------------+\n",
        "|   1920|      vi\u1ec7t nam|\n",
        "|   1920| nh\u1ea1c tr\u1eef t\u00ecnh|\n",
        "|  10154|      vi\u1ec7t nam|\n",
        "|  10154|      nh\u1ea1c tr\u1ebb|\n",
        "|   1305|      vi\u1ec7t nam|\n",
        "|   1305|      nh\u1ea1c tr\u1ebb|\n",
        "|  11583|      vi\u1ec7t nam|\n",
        "|  11583| nh\u1ea1c tr\u1eef t\u00ecnh|\n",
        "|   5228|      vi\u1ec7t nam|\n",
        "|   5228| nh\u1ea1c tr\u1eef t\u00ecnh|\n",
        "|   3076|      vi\u1ec7t nam|\n",
        "|   3076|      nh\u1ea1c tr\u1ebb|\n",
        "|   3158|      vi\u1ec7t nam|\n",
        "|   3158| nh\u1ea1c tr\u1eef t\u00ecnh|\n",
        "|  10861|      vi\u1ec7t nam|\n",
        "|  10861|      nh\u1ea1c tr\u1ebb|\n",
        "|    734|      vi\u1ec7t nam|\n",
        "|    734|      nh\u1ea1c tr\u1ebb|\n",
        "|   6571|      vi\u1ec7t nam|\n",
        "|   6571|nh\u1ea1c c\u00e1ch m\u1ea1ng|\n",
        "+-------+--------------+\n",
        "only showing top 20 rows\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
      "from pyspark.sql.functions import col, udf\n",
      "from pyspark.sql.types import IntegerType\n",
      "\n",
      "sentenceDataFrame = spark.createDataFrame([\n",
      "    (0, \"Hi I heard about Spark\"),\n",
      "    (1, \"I wish Java could use case classes\"),\n",
      "    (2, \"Logistic,regression,models,are,neat\")\n",
      "], [\"id\", \"sentence\"])\n",
      "\n",
      "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
      "\n",
      "regexTokenizer = RegexTokenizer(inputCol=\"sentence\", outputCol=\"words\", pattern=\"\\\\W\")\n",
      "# alternatively, pattern=\"\\\\w+\", gaps(False)\n",
      "\n",
      "countTokens = udf(lambda words: len(words), IntegerType())\n",
      "\n",
      "tokenized = tokenizer.transform(sentenceDataFrame)\n",
      "tokenized.select(\"sentence\", \"words\")\\\n",
      "    .withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=False)\n",
      "\n",
      "regexTokenized = regexTokenizer.transform(sentenceDataFrame)\n",
      "regexTokenized.select(\"sentence\", \"words\") \\\n",
      "    .withColumn(\"tokens\", countTokens(col(\"words\"))).show(truncate=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named numpy",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-aafd15da2952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRegexTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sentenceDataFrame = spark.createDataFrame([\n",
        "\u001b[0;32m/usr/local/spark/python/pyspark/ml/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0mlearning\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnaryTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipelineModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/spark/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msince\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minherit_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/spark/python/pyspark/ml/param/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mabc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mABCMeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_gateway\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJavaObject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named numpy"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}